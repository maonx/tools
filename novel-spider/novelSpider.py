#!/usr/bin/env python3# -*- utf-8 -*-import jsonimport refrom urllib import requestfrom bs4 import BeautifulSoupchapter_patten = re.compile(r'href="(.*\d+.html)" alt="(.*(第+|章+|节+).*)"')def get_books(books_json):    fp = open(books_json, "rt")    books = json.loads(fp.read())    fp.close()    return booksdef save_books(books, books_json):    fp = open(books_json, "wt")    json.dump(books, fp, ensure_ascii=False)    fp.close()def get_update_list(book):    site = 'http://www.ranwen.org/files/article/'+book['shorturl']+'/'+book['bookid']+'/'    catalog = site + 'index.html'    html_content = request.urlopen(catalog).read().decode('gbk')    # return html_content    contentid=book['contentid']    if contentid :        html_content = re.search(r'(?<='+contentid+'.html).*', html_content, re.S).group(0)    # return html_content    # soup = BeautifulSoup(html_content, "html.parser")    # soup = soup.find_all("td", class_="bookinfo_td")[0]    # soup = soup.find_all("a")    # update_list = [ site+x.get('href') for x in soup ]    # update_list=[]    # chapter_re=re.compile(r'.*第.*章.*')    # for x in soup:    #     if chapter_re.match(x.get('alt')):    #         update_list.append(x.get('href'))    # html_content = re.sub(r'href="(?=\d+\.html")', 'href="'+site, html_content)    update_list = chapter_patten.findall(html_content)    # book['contentid']=update_list[-1][0][:-5]    number = book['number']    # new_number = len(update_list)    # book['number'] = new_number    return update_list[number:]def get_chapter(data):    # html_content = request.urlopen(url).read().decode('gbk')    with request.urlopen(data[0]) as f:        html_content = f.read().decode('gbk')    # html_content = html_content.replace('&nbsp;',' ')    # html_content = html_content.replace('<br>','\\r')    content_patten = re.compile(r'name="content".*?</div>(.*?)</(div|DIV)>',re.S)    # soup = BeautifulSoup(html_content, "html.parser")    # name = re.search(r'(?<=chaptername=)\'.*\'',html_content).group(0)    # name = name[1:-1].strip()    # content = soup.find("div",id="content").get_text()    content = content_patten.search(html_content).group(1)    content = content.replace('<br />','\r\n')    name = data[1].strip()    chapter=[name,content]    # chapter={'name':name,'content':content.replace('&nbsp;','')}    return chapterdef output_chapter(chapter):    fp=open(r'temp/'+chapter[0],'w')    fp.write(chapter[1])    fp.close()def main():    books = get_books("books.json")    update_list = get_update_list(books[0])    for i in update_list:        output_chapter(get_chapter(books[0],i))if __name__ == "__main__" :    main()