#!/usr/bin/env python3# -*- utf-8 -*-import jsonimport refrom urllib import requestfrom bs4 import BeautifulSoupdef get_books(books_json):    fp = open(books_json, "rt")    books = json.loads(fp.read())    fp.close()    return booksdef save_books(books, books_json):    fp = open(books_json, "wt")    json.dump(books, fp, ensure_ascii=False)    fp.close()def update_list(book):    site = 'http://www.ranwen.org/files/article/'+book['shorturl']+'/'+book['bookid']+'/'    catalog = site + 'index.html'    html_content = request.urlopen(site).read().decode('gbk')    soup = BeautifulSoup(html_content)    soup = soup.find_all("td", class_="bookinfo_td")[0]    soup = soup.find_all("a")    update_list = [ site+x.get('href') for x in soup ]    # update_list=[]    # chapter_re=re.compile(r'.*第.*章.*')    # for x in soup:    #     if chapter_re.match(x.get('alt')):    #         update_list.append(x.get('href'))    number = book['number']    new_number = len(update_list)    book['number'] = new_number    return update_list[number:]def get_chapter(url):    html_content = request.urlopen(url).read().decode('gbk')    # html_content = html_content.replace('&nbsp;',' ')    # html_content = html_content.replace('<br>','\\r')    soup = BeautifulSoup(html_content)    name = re.search(r'(?<=chaptername=)\'.*\'',html_content).group(0)    name = name[1:-1]    content = soup.find("div",id="content").get_text()    chapter={'name':name,'content':content}    return chapterdef output_chapter(chapter):    fp=open(chapter['name'],'wt')    fp.write(chapter['content'])    fp.close()def main():    books = get_books("books.json")    update_list = update_list(books[0])    for i in update_list:        output_chapter(get_chapter(i))if __name__ == "__main__" :    main()