#!/usr/bin/env python3# -*- utf-8 -*-from urllib import requestimport gzipimport redef ungzip(data):    try:        data = gzip.decompress(data)        return data    except:        print('未经压缩,无需解压')url = 'http://www.ranwen.org/files/article/40/40109/index.html'def get_web(url):    header = {        'Host': 'www.ranwen.org',        'Connection': 'keep-alive',        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',        'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.86 Safari/537.36',        'Accept-Encoding': 'gzip, deflate, sdch',        'Accept-Language': 'en-US,en;q=0.8,zh-CN;q=0.6,zh;q=0.4',    }    try:        req = request.Request(url, headers = header)        page = request.urlopen(req)        page = page.read()        page_data = ungzip(page)        page_data = page_data.decode('gbk')        return page_data    except:        print('url error!')def chapter_list(web):    regex = re.compile(r'<dd><a href="(.*\d+.html)">(.*(第+|章+|节+).*)</a>')    try:        chapters = regex.findall(web)        return chapters    except:        print('web format error')def output_chapter(name,content):    fp=open(r'temp/'+name,'w')    fp.write(content)    fp.close()if __name__ == "__main__" :    catalog = get_web(url)    chapters = chapter_list(catalog)    for i in chapters:        output_chapter(i[1],get_web(i[0]))